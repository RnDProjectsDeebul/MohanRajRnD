{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchmetrics in /opt/conda/lib/python3.9/site-packages (0.11.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from torchmetrics) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.9/site-packages (from torchmetrics) (1.22.4)\n",
      "Requirement already satisfied: torch>=1.8.1 in /opt/conda/lib/python3.9/site-packages (from torchmetrics) (1.11.0+cu113)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torch>=1.8.1->torchmetrics) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging->torchmetrics) (3.0.9)\n",
      "Requirement already satisfied: neptune-client in /opt/conda/lib/python3.9/site-packages (0.16.15)\n",
      "Requirement already satisfied: future>=0.17.1 in /opt/conda/lib/python3.9/site-packages (from neptune-client) (0.18.2)\n",
      "Requirement already satisfied: Pillow>=1.1.6 in /opt/conda/lib/python3.9/site-packages (from neptune-client) (9.2.0)\n",
      "Requirement already satisfied: websocket-client!=1.0.0,>=0.35.0 in /opt/conda/lib/python3.9/site-packages (from neptune-client) (1.3.3)\n",
      "Requirement already satisfied: boto3>=1.16.0 in /opt/conda/lib/python3.9/site-packages (from neptune-client) (1.26.32)\n",
      "Requirement already satisfied: swagger-spec-validator>=2.7.4 in /opt/conda/lib/python3.9/site-packages (from neptune-client) (3.0.3)\n",
      "Requirement already satisfied: PyJWT in /opt/conda/lib/python3.9/site-packages (from neptune-client) (2.4.0)\n",
      "Requirement already satisfied: requests>=2.20.0 in /opt/conda/lib/python3.9/site-packages (from neptune-client) (2.28.1)\n",
      "Requirement already satisfied: oauthlib>=2.1.0 in /opt/conda/lib/python3.9/site-packages (from neptune-client) (3.2.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from neptune-client) (1.4.3)\n",
      "Requirement already satisfied: requests-oauthlib>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from neptune-client) (1.3.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.9/site-packages (from neptune-client) (1.16.0)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.9/site-packages (from neptune-client) (1.26.11)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.9/site-packages (from neptune-client) (8.1.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.9/site-packages (from neptune-client) (5.9.1)\n",
      "Requirement already satisfied: GitPython>=2.0.8 in /opt/conda/lib/python3.9/site-packages (from neptune-client) (3.1.29)\n",
      "Requirement already satisfied: bravado<12.0.0,>=11.0.0 in /opt/conda/lib/python3.9/site-packages (from neptune-client) (11.0.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from neptune-client) (21.3)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.32 in /opt/conda/lib/python3.9/site-packages (from boto3>=1.16.0->neptune-client) (1.29.32)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.9/site-packages (from boto3>=1.16.0->neptune-client) (0.6.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.9/site-packages (from boto3>=1.16.0->neptune-client) (1.0.1)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.9/site-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (6.0)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.9/site-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (2.8.2)\n",
      "Requirement already satisfied: bravado-core>=5.16.1 in /opt/conda/lib/python3.9/site-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (5.17.1)\n",
      "Requirement already satisfied: monotonic in /opt/conda/lib/python3.9/site-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (1.6)\n",
      "Requirement already satisfied: msgpack in /opt/conda/lib/python3.9/site-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (1.0.4)\n",
      "Requirement already satisfied: simplejson in /opt/conda/lib/python3.9/site-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (4.3.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.9/site-packages (from GitPython>=2.0.8->neptune-client) (4.0.10)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.9/site-packages (from requests>=2.20.0->neptune-client) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests>=2.20.0->neptune-client) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests>=2.20.0->neptune-client) (3.3)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.9/site-packages (from swagger-spec-validator>=2.7.4->neptune-client) (4.9.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging->neptune-client) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas->neptune-client) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.9/site-packages (from pandas->neptune-client) (1.22.4)\n",
      "Requirement already satisfied: jsonref in /opt/conda/lib/python3.9/site-packages (from bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client) (1.0.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->GitPython>=2.0.8->neptune-client) (5.0.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.9/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (0.18.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.9/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (22.1.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /opt/conda/lib/python3.9/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (2.3)\n",
      "Requirement already satisfied: isoduration in /opt/conda/lib/python3.9/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (20.11.0)\n",
      "Requirement already satisfied: fqdn in /opt/conda/lib/python3.9/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (1.5.1)\n",
      "Requirement already satisfied: rfc3987 in /opt/conda/lib/python3.9/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (1.3.8)\n",
      "Requirement already satisfied: uri-template in /opt/conda/lib/python3.9/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (1.2.0)\n",
      "Requirement already satisfied: rfc3339-validator in /opt/conda/lib/python3.9/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (0.1.4)\n",
      "Requirement already satisfied: webcolors>=1.11 in /opt/conda/lib/python3.9/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (1.12)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /opt/conda/lib/python3.9/site-packages (from isoduration->jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (1.2.3)\n",
      "Requirement already satisfied: scikit-plot in /opt/conda/lib/python3.9/site-packages (0.3.7)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /opt/conda/lib/python3.9/site-packages (from scikit-plot) (1.1.2)\n",
      "Requirement already satisfied: scipy>=0.9 in /opt/conda/lib/python3.9/site-packages (from scikit-plot) (1.8.1)\n",
      "Requirement already satisfied: joblib>=0.10 in /opt/conda/lib/python3.9/site-packages (from scikit-plot) (1.1.0)\n",
      "Requirement already satisfied: matplotlib>=1.4.0 in /opt/conda/lib/python3.9/site-packages (from scikit-plot) (3.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=1.4.0->scikit-plot) (1.22.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=1.4.0->scikit-plot) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=1.4.0->scikit-plot) (4.34.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=1.4.0->scikit-plot) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=1.4.0->scikit-plot) (9.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=1.4.0->scikit-plot) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=1.4.0->scikit-plot) (3.0.9)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn>=0.18->scikit-plot) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=1.4.0->scikit-plot) (1.16.0)\n",
      "Requirement already satisfied: ray[tune] in /opt/conda/lib/python3.9/site-packages (2.2.0)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /opt/conda/lib/python3.9/site-packages (from ray[tune]) (1.22.4)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.9/site-packages (from ray[tune]) (4.9.1)\n",
      "Requirement already satisfied: virtualenv>=20.0.24 in /opt/conda/lib/python3.9/site-packages (from ray[tune]) (20.17.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from ray[tune]) (2.28.1)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.9/site-packages (from ray[tune]) (6.0)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /opt/conda/lib/python3.9/site-packages (from ray[tune]) (3.20.1)\n",
      "Requirement already satisfied: frozenlist in /opt/conda/lib/python3.9/site-packages (from ray[tune]) (1.3.3)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.9/site-packages (from ray[tune]) (8.1.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from ray[tune]) (3.8.2)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from ray[tune]) (1.0.4)\n",
      "Requirement already satisfied: grpcio>=1.32.0 in /opt/conda/lib/python3.9/site-packages (from ray[tune]) (1.47.0)\n",
      "Requirement already satisfied: attrs in /opt/conda/lib/python3.9/site-packages (from ray[tune]) (22.1.0)\n",
      "Requirement already satisfied: aiosignal in /opt/conda/lib/python3.9/site-packages (from ray[tune]) (1.3.1)\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.9/site-packages (from ray[tune]) (0.9.0)\n",
      "Requirement already satisfied: tensorboardX>=1.9 in /opt/conda/lib/python3.9/site-packages (from ray[tune]) (2.5.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from ray[tune]) (1.4.3)\n",
      "Requirement already satisfied: six>=1.5.2 in /opt/conda/lib/python3.9/site-packages (from grpcio>=1.32.0->ray[tune]) (1.16.0)\n",
      "Requirement already satisfied: platformdirs<3,>=2.4 in /opt/conda/lib/python3.9/site-packages (from virtualenv>=20.0.24->ray[tune]) (2.6.0)\n",
      "Requirement already satisfied: distlib<1,>=0.3.6 in /opt/conda/lib/python3.9/site-packages (from virtualenv>=20.0.24->ray[tune]) (0.3.6)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.9/site-packages (from jsonschema->ray[tune]) (0.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.9/site-packages (from pandas->ray[tune]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas->ray[tune]) (2022.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.9/site-packages (from requests->ray[tune]) (2.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->ray[tune]) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->ray[tune]) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->ray[tune]) (3.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchmetrics\n",
    "!pip install neptune-client\n",
    "!pip install scikit-plot\n",
    "!pip install -U \"ray[tune]\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from torchmetrics import Accuracy\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.models import resnet18,mobilenet_v2\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import glob\n",
    "import seaborn as sn\n",
    "from functools import partial\n",
    "from datetime import datetime\n",
    "import scipy.ndimage as nd\n",
    "import neptune.new as neptune\n",
    "from sklearn.metrics import confusion_matrix ,classification_report,accuracy_score,f1_score,precision_score,recall_score\n",
    "from scikitplot.metrics import plot_confusion_matrix\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26461/2058017951.py:12: NeptuneDeprecationWarning: `init` is deprecated, use `init_run` instead. We'll end support of it in `neptune-client==1.0.0`.\n",
      "  nep_logger = neptune.init(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/mohan20325145/resnet/e/RESNETNEP-169\n",
      "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    }
   ],
   "source": [
    "#General\n",
    "data_dir = os.path.abspath(\"./data\")\n",
    "classes  = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "class_len = len(classes)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "training_config  = 0\n",
    "train_accuracy = Accuracy(task=\"multiclass\", num_classes = class_len)\n",
    "train_accuracy.to(device)\n",
    "l1 = l2 = lr = batch_size = 0\n",
    "\n",
    "tnsr_board_logger = SummaryWriter()\n",
    "nep_logger = neptune.init(\n",
    "project=\"mohan20325145/resnet\",\n",
    "api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJhZWQyMTU4OC02NmU4LTRiNjgtYWE5Zi1lNDg5MjdmZGJhNzYifQ==\",)\n",
    "\n",
    "\n",
    "#Tuning \n",
    "tune_hyperparams = False\n",
    "num_samples = 4\n",
    "max_num_epochs = 3\n",
    "gpus_per_trial = 0 \n",
    "\n",
    "\n",
    "#Training\n",
    "num_workers = 8 #2\n",
    "epochs = [100]\n",
    "optimizer = [\"Adam\"]\n",
    "criterion = [nn.CrossEntropyLoss(), \"Evidential\"]\n",
    "model = [\"ResNet\"]\n",
    "train_network = True\n",
    "test_network = False\n",
    "save_model_params = True\n",
    "\n",
    "#num_workers = [2,3]\n",
    "#criterion = [\"Evidential\", nn.CrossEntropyLoss(), nn.NLLLoss(), nn.GaussianNLLLoss(), nn.SoftMarginLoss()] \n",
    "#optimizer = [\"Adam\", \"SGD\", \"ASGD\", \"Adamax\"]\n",
    "#epochs = [40, 100]\n",
    "#model = [\"ResNet\", \"MobileNet\", \"CustomNet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir):\n",
    "    transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    trainset = torchvision.datasets.CIFAR10(root=data_dir, train=True, download=True, transform=transform)\n",
    "    testset = torchvision.datasets.CIFAR10(root=data_dir, train=False, download=True, transform=transform)\n",
    "#     trainset = torchvision.datasets.MNIST(root=data_dir, train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "#     testset = torchvision.datasets.MNIST(root=data_dir, train=False, download=True, transform=transforms.Compose([transforms.ToTensor()]))    \n",
    "    return trainset, testset\n",
    "\n",
    "def logger():\n",
    "    nep_logger.stop()\n",
    "    tnsr_board_logger.close\n",
    "    # !tensorboard --logdir=runs\n",
    "\n",
    "class Param_Tuning_NN(nn.Module):\n",
    "    def __init__(self, l1, l2):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, l1)\n",
    "        self.fc2 = nn.Linear(l1, l2)\n",
    "        self.fc3 = nn.Linear(l2, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)   \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x  \n",
    "    \n",
    "class Custom_Train_NN(nn.Module):\n",
    "    def __init__(self, l1, l2):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, l1)\n",
    "        self.fc2 = nn.Linear(l1, l2)\n",
    "        self.fc3 = nn.Linear(l2, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x,1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_subroutine(config, checkpoint_dir=None, data_dir=None):\n",
    "    \n",
    "    net = Param_Tuning_NN(config[\"l1\"], config[\"l2\"])\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            net = nn.DataParallel(net)\n",
    "    net.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=config[\"lr\"], momentum=0.9)\n",
    "\n",
    "    if checkpoint_dir:\n",
    "        model_state, optimizer_state = torch.load(os.path.join(checkpoint_dir, \"checkpoint\"))\n",
    "        net.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "        \n",
    "    trainset, testset = load_data(data_dir)\n",
    "    test_abs = int(len(trainset) * 0.8)\n",
    "    train_subset, val_subset = random_split(trainset, [test_abs, len(trainset) - test_abs])\n",
    "    trainloader = torch.utils.data.DataLoader(train_subset, batch_size=int(config[\"batch_size\"]), shuffle=True, num_workers=8)\n",
    "    valloader = torch.utils.data.DataLoader(val_subset, batch_size=int(config[\"batch_size\"]), shuffle=True, num_workers=8)\n",
    "\n",
    "    for epoch in range(10):\n",
    "        running_loss = 0.0\n",
    "        epoch_steps = 0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        val_loss = 0.0\n",
    "        val_steps = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for i, data in enumerate(valloader, 0):\n",
    "            with torch.no_grad():\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = net(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.cpu().numpy()\n",
    "                val_steps += 1\n",
    "        with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
    "            path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "            torch.save((net.state_dict(), optimizer.state_dict()), path)\n",
    "        tune.report(loss=(val_loss / val_steps), accuracy=correct / total)\n",
    "    \n",
    "    \n",
    "def tune_model():\n",
    "    config = {\"l1\": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),\n",
    "              \"l2\": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),\n",
    "              \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "              \"batch_size\": tune.choice([2, 4, 8, 16])}\n",
    "    scheduler = ASHAScheduler(metric=\"loss\",\n",
    "                              mode=\"min\",\n",
    "                              max_t=max_num_epochs,\n",
    "                              grace_period=1,\n",
    "                              reduction_factor=2)\n",
    "    reporter = CLIReporter(metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n",
    "    result = tune.run(partial(tune_subroutine, data_dir=data_dir),\n",
    "             resources_per_trial={\"cpu\": 2, \"gpu\": gpus_per_trial},\n",
    "             config=config,\n",
    "             num_samples=num_samples,\n",
    "             scheduler=scheduler,\n",
    "             progress_reporter=reporter)\n",
    "\n",
    "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "    print(\"Best trial config: {}\".format(best_trial.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(best_trial.last_result[\"loss\"]))\n",
    "    print(\"Best trial final validation accuracy: {}\".format(best_trial.last_result[\"accuracy\"]))\n",
    "    return best_trial.config['l1'], best_trial.config['l2'], best_trial.config['lr'], best_trial.config['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_embedding(labels, num_classes):\n",
    "    y = torch.eye(num_classes)\n",
    "    return y[labels]\n",
    "\n",
    "def relu_evidence(y):\n",
    "    return F.relu(y)\n",
    "\n",
    "def kl_divergence(alpha, num_classes, device=None):\n",
    "    beta = torch.ones([1, num_classes], dtype=torch.float32, device=device)\n",
    "    S_alpha = torch.sum(alpha, dim=1, keepdim=True)\n",
    "    S_beta = torch.sum(beta, dim=1, keepdim=True)\n",
    "    lnB = torch.lgamma(S_alpha) - torch.sum(torch.lgamma(alpha), dim=1, keepdim=True)\n",
    "    lnB_uni = torch.sum(torch.lgamma(beta), dim=1, keepdim=True) - torch.lgamma(S_beta)\n",
    "    dg0 = torch.digamma(S_alpha)\n",
    "    dg1 = torch.digamma(alpha)\n",
    "    kl = torch.sum((alpha - beta) * (dg1 - dg0), dim=1, keepdim=True) + lnB + lnB_uni\n",
    "    return kl\n",
    "\n",
    "def loglikelihood_loss(y, alpha, device=None):\n",
    "    y = y.to(device)\n",
    "    alpha = alpha.to(device)\n",
    "    S = torch.sum(alpha, dim=1, keepdim=True)\n",
    "    loglikelihood_err = torch.sum((y - (alpha / S)) ** 2, dim=1, keepdim=True)\n",
    "    loglikelihood_var = torch.sum(alpha * (S - alpha) / (S * S * (S + 1)), dim=1, keepdim=True)\n",
    "    loglikelihood = loglikelihood_err + loglikelihood_var\n",
    "    return loglikelihood\n",
    "\n",
    "def mse_loss(y, alpha, epoch_num, num_classes, annealing_step, device=None):\n",
    "    y = y.to(device)\n",
    "    alpha = alpha.to(device)\n",
    "    loglikelihood = loglikelihood_loss(y, alpha, device=device)\n",
    "    annealing_coef = torch.min(torch.tensor(1.0, dtype=torch.float32), torch.tensor(epoch_num / annealing_step, dtype=torch.float32))\n",
    "    kl_alpha = (alpha - 1) * (1 - y) + 1\n",
    "    kl_div = annealing_coef * kl_divergence(kl_alpha, num_classes, device=device)\n",
    "    return loglikelihood + kl_div\n",
    "\n",
    "def edl_mse_loss(output, target, epoch_num, num_classes, annealing_step, device=None):\n",
    "    evidence = relu_evidence(output)\n",
    "    alpha = evidence + 1\n",
    "    loss = torch.mean(mse_loss(target, alpha, epoch_num, num_classes, annealing_step, device=device))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_subroutine(criterion_, optimizer_, epochs_, model_):\n",
    "    since = time.time()\n",
    "    nep_logger['params/training/model'+ str(training_config)].log(model_)\n",
    "    nep_logger['params/training/model'+ str(training_config)].log(criterion_)\n",
    "    nep_logger['params/training/model'+ str(training_config)].log(epochs_)\n",
    "    nep_logger['params/training/model'+ str(training_config)].log(optimizer_)\n",
    "    \n",
    "    if (model_ == \"ResNet\"):\n",
    "        net = resnet18()\n",
    "        net.fc = nn.Linear(in_features=512,out_features=class_len)\n",
    "    elif (model_ == \"MobileNet\"):\n",
    "        net = mobilenet_v2()\n",
    "        net.fc = nn.Linear(in_features=512,out_features=class_len)\n",
    "    elif (model_ == \"CustomNet\"):\n",
    "        net = Custom_Train_NN(l1, l2)   \n",
    "\n",
    "    if (optimizer_ == \"Adam\"):\n",
    "        optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=0.005)\n",
    "    elif (optimizer_ == \"SGD\"):\n",
    "        optimizer = optim.SGD(net.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "   \n",
    "    net = net.to(device)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    valloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, num_workers=num_workers)\n",
    "    dataloaders = {\"train\": trainloader, \"val\": valloader,}\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(net.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    losses = {\"loss\": [], \"phase\": [], \"epoch\": []}\n",
    "    accuracy = {\"accuracy\": [], \"phase\": [], \"epoch\": []}\n",
    "    \n",
    "    for epoch in range(epochs_):\n",
    "        print(\"Epoch {}/{}\".format(epoch, epochs_ - 1))\n",
    "        print(\"-\" * 10)\n",
    "        \n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                print(\"Training...\")\n",
    "                net.train()  \n",
    "            else:\n",
    "                print(\"Validating...\")\n",
    "                net.eval()\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0.0\n",
    "            \n",
    "            for i, data in enumerate(dataloaders[phase]):\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = net(inputs)\n",
    "                _,predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    if criterion_ == \"Evidential\":\n",
    "                        y = one_hot_embedding(labels=labels,num_classes=class_len)\n",
    "                        y.to(device)\n",
    "                        loss = edl_mse_loss(outputs, y.float(), epoch, class_len, 10, device)\n",
    "                        match = torch.reshape(torch.eq(predicted, labels).float(), (-1, 1))\n",
    "                        acc = torch.mean(match)\n",
    "                        evidence = relu_evidence(outputs)    \n",
    "                        alpha = evidence + 1\n",
    "                        u = class_len / torch.sum(alpha, dim=1, keepdim=True)\n",
    "                        total_evidence = torch.sum(evidence, 1, keepdim=True)\n",
    "                        mean_evidence = torch.mean(total_evidence)\n",
    "                        mean_evidence_succ = torch.sum(torch.sum(evidence, 1, keepdim=True) * match) / torch.sum(match + 1e-20)\n",
    "                        mean_evidence_fail = torch.sum(torch.sum(evidence, 1, keepdim=True) * (1 - match)) / (torch.sum(torch.abs(1 - match)) + 1e-20)\n",
    "                    else:\n",
    "                        loss = criterion_(outputs, labels)\n",
    "                    \n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                running_loss += loss.item()* inputs.size(0)\n",
    "                running_corrects += torch.sum(predicted == labels.data)\n",
    "            \n",
    "            epoch_loss = running_loss / len(trainloader)\n",
    "            epoch_acc = running_corrects.double() / len(trainloader)\n",
    "            \n",
    "            if phase == \"train\":\n",
    "                nep_logger['plots/training/train/loss'+ str(training_config)].log(epoch_loss)\n",
    "                nep_logger['plots/training/train/accuracy'+ str(training_config)].log(epoch_acc.item())\n",
    "            else:\n",
    "                nep_logger['plots/training/val/loss'+ str(training_config)].log(epoch_loss)\n",
    "                nep_logger['plots/training/val/accuracy'+ str(training_config)].log(epoch_acc.item())\n",
    "                \n",
    "            losses[\"loss\"].append(epoch_loss)\n",
    "            losses[\"phase\"].append(phase)\n",
    "            losses[\"epoch\"].append(epoch)\n",
    "            accuracy[\"accuracy\"].append(epoch_acc.item())\n",
    "            accuracy[\"epoch\"].append(epoch)\n",
    "            accuracy[\"phase\"].append(phase)\n",
    "            \n",
    "            print(\"{} loss: {:.4f} acc: {:.4f}\".format(phase.capitalize(), epoch_loss, epoch_acc))\n",
    "\n",
    "            if phase == \"val\" and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(net.state_dict())\n",
    "                \n",
    "                \n",
    "    time_elapsed = time.time() - since\n",
    "    print(\"Training complete in {:.0f}m {:.0f}s\".format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print(\"Best val Acc: {:4f}\".format(best_acc))\n",
    "    \n",
    "    net.load_state_dict(best_model_wts)\n",
    "\n",
    "    if save_model_params:\n",
    "        state = {\"epoch\": epochs_,\n",
    "                 \"model_state_dict\": net.state_dict(),\n",
    "                 \"optimizer_state_dict\": optimizer.state_dict()}\n",
    "        \n",
    "        if criterion_ == \"Evidential\":\n",
    "            saved_models_count = len('./results/EDL/*')\n",
    "            torch.save(state, \"./results/EDL/\"+ str(saved_models_count+1)+\".pt\")\n",
    "        else:\n",
    "            saved_models_count = len('./results/CEL/*')\n",
    "            torch.save(state, \"./results/CEL/\"+ str(saved_models_count+1)+\".pt\")\n",
    "    \n",
    "\n",
    "def train_model():\n",
    "    global training_config\n",
    "    for loss, opti, epo, mod in [(loss, opti, epo, mod) for loss in criterion for opti in optimizer for epo in epochs for mod in model]:\n",
    "        training_config += 1\n",
    "        train_model_subroutine(loss, opti, epo, mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model():\n",
    "    for loss, mod in [(loss, mod) for loss in criterion for mod in model]:\n",
    "        if loss == \"Evidential\":\n",
    "            saved_models_count = len('./results/EDL/*')\n",
    "            checkpoint = torch.load(\"./results/EDL/\"+str(saved_models_count)+\".pt\")\n",
    "            \n",
    "        else:\n",
    "            saved_models_count = len('./results/CEL/*')\n",
    "            checkpoint = torch.load(\"./results/CEL/\"+str(saved_models_count)+\".pt\")\n",
    "            \n",
    "        if (model_ == \"ResNet\"):\n",
    "            net = resnet18()\n",
    "            net.fc = nn.Linear(in_features=512,out_features=class_len)\n",
    "            \n",
    "        optimizer = optim.Adam(net.parameters())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 0/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 25.9319 acc: 6.6458\n",
      "Validating...\n",
      "Val loss: 4.6156 acc: 1.5434\n",
      "Epoch 1/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 21.1859 acc: 8.5642\n",
      "Validating...\n",
      "Val loss: 3.8160 acc: 1.8726\n",
      "Epoch 2/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 18.9580 acc: 9.4230\n",
      "Validating...\n",
      "Val loss: 3.6290 acc: 1.9146\n",
      "Epoch 3/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 17.8179 acc: 9.8064\n",
      "Validating...\n",
      "Val loss: 3.2977 acc: 2.0573\n",
      "Epoch 4/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 17.3261 acc: 10.0138\n",
      "Validating...\n",
      "Val loss: 3.2929 acc: 2.0490\n",
      "Epoch 5/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 16.8092 acc: 10.2765\n",
      "Validating...\n",
      "Val loss: 3.1625 acc: 2.0982\n",
      "Epoch 6/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 16.6233 acc: 10.2774\n",
      "Validating...\n",
      "Val loss: 3.1175 acc: 2.1261\n",
      "Epoch 7/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 16.2880 acc: 10.4586\n",
      "Validating...\n",
      "Val loss: 3.2162 acc: 2.1040\n",
      "Epoch 8/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 16.1877 acc: 10.4906\n",
      "Validating...\n",
      "Val loss: 3.1060 acc: 2.1405\n",
      "Epoch 9/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 16.1244 acc: 10.4957\n",
      "Validating...\n",
      "Val loss: 3.2440 acc: 2.0864\n",
      "Epoch 10/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.9773 acc: 10.5520\n",
      "Validating...\n",
      "Val loss: 3.0766 acc: 2.1382\n",
      "Epoch 11/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.9393 acc: 10.5472\n",
      "Validating...\n",
      "Val loss: 3.1816 acc: 2.1219\n",
      "Epoch 12/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.8381 acc: 10.6147\n",
      "Validating...\n",
      "Val loss: 3.1288 acc: 2.1168\n",
      "Epoch 13/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.7367 acc: 10.6627\n",
      "Validating...\n",
      "Val loss: 3.0396 acc: 2.1504\n",
      "Epoch 14/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.7871 acc: 10.6330\n",
      "Validating...\n",
      "Val loss: 2.9368 acc: 2.1942\n",
      "Epoch 15/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.5983 acc: 10.6966\n",
      "Validating...\n",
      "Val loss: 3.3788 acc: 2.0176\n",
      "Epoch 16/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6184 acc: 10.6726\n",
      "Validating...\n",
      "Val loss: 3.0179 acc: 2.1606\n",
      "Epoch 17/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.5814 acc: 10.7011\n",
      "Validating...\n",
      "Val loss: 3.0515 acc: 2.1616\n",
      "Epoch 18/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.5813 acc: 10.7018\n",
      "Validating...\n",
      "Val loss: 3.0222 acc: 2.1734\n",
      "Epoch 19/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.5075 acc: 10.7328\n",
      "Validating...\n",
      "Val loss: 3.0612 acc: 2.1386\n",
      "Epoch 20/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.4517 acc: 10.7517\n",
      "Validating...\n",
      "Val loss: 2.9662 acc: 2.1872\n",
      "Epoch 21/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.4792 acc: 10.7158\n",
      "Validating...\n",
      "Val loss: 3.0016 acc: 2.1770\n",
      "Epoch 22/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.5150 acc: 10.6998\n",
      "Validating...\n",
      "Val loss: 2.9285 acc: 2.1978\n",
      "Epoch 23/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.3873 acc: 10.7622\n",
      "Validating...\n",
      "Val loss: 3.0035 acc: 2.1677\n",
      "Epoch 24/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.4532 acc: 10.7440\n",
      "Validating...\n",
      "Val loss: 3.0320 acc: 2.1443\n",
      "Epoch 25/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.3155 acc: 10.8048\n",
      "Validating...\n",
      "Val loss: 2.9818 acc: 2.1686\n",
      "Epoch 26/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.2320 acc: 10.8371\n",
      "Validating...\n",
      "Val loss: 2.9132 acc: 2.1808\n",
      "Epoch 27/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.3138 acc: 10.8195\n",
      "Validating...\n",
      "Val loss: 3.1308 acc: 2.1206\n",
      "Epoch 28/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.2724 acc: 10.7882\n",
      "Validating...\n",
      "Val loss: 2.9104 acc: 2.2202\n",
      "Epoch 29/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.3679 acc: 10.7421\n",
      "Validating...\n",
      "Val loss: 2.8881 acc: 2.2077\n",
      "Epoch 30/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.2346 acc: 10.8195\n",
      "Validating...\n",
      "Val loss: 2.9540 acc: 2.1782\n",
      "Epoch 31/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.2422 acc: 10.8413\n",
      "Validating...\n",
      "Val loss: 3.0761 acc: 2.1530\n",
      "Epoch 32/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.2361 acc: 10.8125\n",
      "Validating...\n",
      "Val loss: 3.2410 acc: 2.0899\n",
      "Epoch 33/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.1035 acc: 10.8723\n",
      "Validating...\n",
      "Val loss: 2.9888 acc: 2.1786\n",
      "Epoch 34/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.1250 acc: 10.8480\n",
      "Validating...\n",
      "Val loss: 2.9814 acc: 2.1962\n",
      "Epoch 35/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.0811 acc: 10.8618\n",
      "Validating...\n",
      "Val loss: 3.0573 acc: 2.1670\n",
      "Epoch 36/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.1264 acc: 10.8560\n",
      "Validating...\n",
      "Val loss: 3.0493 acc: 2.1424\n",
      "Epoch 37/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.1015 acc: 10.8758\n",
      "Validating...\n",
      "Val loss: 2.9336 acc: 2.1981\n",
      "Epoch 38/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.0623 acc: 10.8899\n",
      "Validating...\n",
      "Val loss: 3.1509 acc: 2.1222\n",
      "Epoch 39/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.9990 acc: 10.9062\n",
      "Validating...\n",
      "Val loss: 2.9980 acc: 2.1722\n",
      "Epoch 40/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.0655 acc: 10.8614\n",
      "Validating...\n",
      "Val loss: 2.8587 acc: 2.2285\n",
      "Epoch 41/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.9729 acc: 10.8886\n",
      "Validating...\n",
      "Val loss: 2.8745 acc: 2.2384\n",
      "Epoch 42/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.0083 acc: 10.9242\n",
      "Validating...\n",
      "Val loss: 2.8683 acc: 2.2096\n",
      "Epoch 43/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.9842 acc: 10.8698\n",
      "Validating...\n",
      "Val loss: 2.9683 acc: 2.1930\n",
      "Epoch 44/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.0460 acc: 10.8966\n",
      "Validating...\n",
      "Val loss: 3.0256 acc: 2.1648\n",
      "Epoch 45/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.9604 acc: 10.9024\n",
      "Validating...\n",
      "Val loss: 2.8773 acc: 2.2304\n",
      "Epoch 46/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.0343 acc: 10.9056\n",
      "Validating...\n",
      "Val loss: 3.0913 acc: 2.1398\n",
      "Epoch 47/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.0911 acc: 10.8912\n",
      "Validating...\n",
      "Val loss: 3.0558 acc: 2.1485\n",
      "Epoch 48/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.0483 acc: 10.9136\n",
      "Validating...\n",
      "Val loss: 2.9208 acc: 2.1942\n",
      "Epoch 49/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.9442 acc: 10.9229\n",
      "Validating...\n",
      "Val loss: 2.9804 acc: 2.1693\n",
      "Epoch 50/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.9632 acc: 10.9446\n",
      "Validating...\n",
      "Val loss: 2.9403 acc: 2.1939\n",
      "Epoch 51/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.9679 acc: 10.9126\n",
      "Validating...\n",
      "Val loss: 3.0619 acc: 2.1459\n",
      "Epoch 52/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.0333 acc: 10.8528\n",
      "Validating...\n",
      "Val loss: 2.9415 acc: 2.1802\n",
      "Epoch 53/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.9673 acc: 10.9258\n",
      "Validating...\n",
      "Val loss: 2.9230 acc: 2.2026\n",
      "Epoch 54/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.0307 acc: 10.9270\n",
      "Validating...\n",
      "Val loss: 3.0377 acc: 2.1494\n",
      "Epoch 55/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.9746 acc: 10.9437\n",
      "Validating...\n",
      "Val loss: 3.0655 acc: 2.1578\n",
      "Epoch 56/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.8803 acc: 10.9184\n",
      "Validating...\n",
      "Val loss: 2.8532 acc: 2.2317\n",
      "Epoch 57/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.9180 acc: 10.9171\n",
      "Validating...\n",
      "Val loss: 3.1060 acc: 2.1382\n",
      "Epoch 58/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.8979 acc: 10.9622\n",
      "Validating...\n",
      "Val loss: 3.0851 acc: 2.1533\n",
      "Epoch 59/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.8512 acc: 10.9494\n",
      "Validating...\n",
      "Val loss: 3.0030 acc: 2.1594\n",
      "Epoch 60/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.9163 acc: 10.9370\n",
      "Validating...\n",
      "Val loss: 2.9458 acc: 2.1866\n",
      "Epoch 61/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.9788 acc: 10.9120\n",
      "Validating...\n",
      "Val loss: 3.0554 acc: 2.1373\n",
      "Epoch 62/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.9351 acc: 10.8643\n",
      "Validating...\n",
      "Val loss: 3.0158 acc: 2.1699\n",
      "Epoch 63/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.9374 acc: 10.8890\n",
      "Validating...\n",
      "Val loss: 3.0022 acc: 2.1683\n",
      "Epoch 64/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.9204 acc: 10.9021\n",
      "Validating...\n",
      "Val loss: 2.9712 acc: 2.1722\n",
      "Epoch 65/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.9816 acc: 10.9261\n",
      "Validating...\n",
      "Val loss: 2.9795 acc: 2.1773\n",
      "Epoch 66/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.9321 acc: 10.9146\n",
      "Validating...\n",
      "Val loss: 2.9574 acc: 2.1811\n",
      "Epoch 67/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.9174 acc: 10.9318\n",
      "Validating...\n",
      "Val loss: 2.9764 acc: 2.1626\n",
      "Epoch 68/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.8944 acc: 10.9392\n",
      "Validating...\n",
      "Val loss: 2.9304 acc: 2.2032\n",
      "Epoch 69/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.8827 acc: 10.9155\n",
      "Validating...\n",
      "Val loss: 2.8545 acc: 2.2310\n",
      "Epoch 70/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.8739 acc: 10.9219\n",
      "Validating...\n",
      "Val loss: 3.0736 acc: 2.1315\n",
      "Epoch 71/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.8963 acc: 10.9226\n",
      "Validating...\n",
      "Val loss: 2.9334 acc: 2.1962\n",
      "Epoch 72/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.9395 acc: 10.9203\n",
      "Validating...\n",
      "Val loss: 2.9573 acc: 2.2070\n",
      "Epoch 73/99\n",
      "----------\n",
      "Training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 14.8203 acc: 10.9728\n",
      "Validating...\n",
      "Val loss: 2.9502 acc: 2.1552\n",
      "Epoch 74/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.8232 acc: 10.9760\n",
      "Validating...\n",
      "Val loss: 2.9230 acc: 2.1914\n",
      "Epoch 75/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.8442 acc: 10.9514\n",
      "Validating...\n",
      "Val loss: 2.9324 acc: 2.1990\n",
      "Epoch 76/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.8559 acc: 10.9731\n",
      "Validating...\n",
      "Val loss: 2.9308 acc: 2.1971\n",
      "Epoch 77/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.8240 acc: 10.9453\n",
      "Validating...\n",
      "Val loss: 2.9783 acc: 2.1757\n",
      "Epoch 78/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.8982 acc: 10.9338\n",
      "Validating...\n",
      "Val loss: 3.0288 acc: 2.1626\n",
      "Epoch 79/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.8127 acc: 10.9917\n",
      "Validating...\n",
      "Val loss: 2.9519 acc: 2.1610\n",
      "Epoch 80/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.8537 acc: 10.9680\n",
      "Validating...\n",
      "Val loss: 2.9389 acc: 2.1987\n",
      "Epoch 81/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.8711 acc: 10.9552\n",
      "Validating...\n",
      "Val loss: 2.9130 acc: 2.1907\n",
      "Epoch 82/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.8691 acc: 10.9549\n",
      "Validating...\n",
      "Val loss: 2.8944 acc: 2.2074\n",
      "Epoch 83/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.8726 acc: 10.9610\n",
      "Validating...\n",
      "Val loss: 3.1825 acc: 2.0966\n",
      "Epoch 84/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.8613 acc: 10.9594\n",
      "Validating...\n",
      "Val loss: 2.9013 acc: 2.2080\n",
      "Epoch 85/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.9002 acc: 10.9440\n",
      "Validating...\n",
      "Val loss: 2.8986 acc: 2.2019\n",
      "Epoch 86/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.8397 acc: 10.9222\n",
      "Validating...\n",
      "Val loss: 3.0019 acc: 2.1690\n",
      "Epoch 87/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.8862 acc: 10.9584\n",
      "Validating...\n",
      "Val loss: 2.8435 acc: 2.2339\n",
      "Epoch 88/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.8564 acc: 10.9709\n",
      "Validating...\n",
      "Val loss: 2.9780 acc: 2.1888\n",
      "Epoch 89/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.8835 acc: 10.9427\n",
      "Validating...\n",
      "Val loss: 2.9525 acc: 2.1946\n",
      "Epoch 90/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.7966 acc: 10.9830\n",
      "Validating...\n",
      "Val loss: 3.0069 acc: 2.1821\n",
      "Epoch 91/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.8363 acc: 10.9875\n",
      "Validating...\n",
      "Val loss: 2.9912 acc: 2.1696\n",
      "Epoch 92/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.7783 acc: 10.9805\n",
      "Validating...\n",
      "Val loss: 3.0531 acc: 2.1517\n",
      "Epoch 93/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.8580 acc: 10.9146\n",
      "Validating...\n",
      "Val loss: 2.9020 acc: 2.2058\n",
      "Epoch 94/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.7990 acc: 10.9725\n",
      "Validating...\n",
      "Val loss: 2.9840 acc: 2.1722\n",
      "Epoch 95/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.8445 acc: 10.9562\n",
      "Validating...\n",
      "Val loss: 3.0218 acc: 2.1770\n",
      "Epoch 96/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.8611 acc: 10.9482\n",
      "Validating...\n",
      "Val loss: 2.9914 acc: 2.1750\n",
      "Epoch 97/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.8628 acc: 10.9763\n",
      "Validating...\n",
      "Val loss: 2.8972 acc: 2.2032\n",
      "Epoch 98/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.8125 acc: 10.9613\n",
      "Validating...\n",
      "Val loss: 2.9130 acc: 2.2051\n",
      "Epoch 99/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 14.8335 acc: 10.9658\n",
      "Validating...\n",
      "Val loss: 2.9963 acc: 2.1725\n",
      "Training complete in 98m 20s\n",
      "Best val Acc: 2.238400\n",
      "Epoch 0/99\n",
      "----------\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26461/29867075.py:12: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /home/jovyan/.cache//torch/kernels. This warning will appear only once per process. (Triggered internally at  ../aten/src/ATen/native/cuda/jit_utils.cpp:860.)\n",
      "  lnB = torch.lgamma(S_alpha) - torch.sum(torch.lgamma(alpha), dim=1, keepdim=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 13.8136 acc: 3.9840\n",
      "Validating...\n",
      "Val loss: 2.6865 acc: 0.9158\n",
      "Epoch 1/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.2578 acc: 4.7062\n",
      "Validating...\n",
      "Val loss: 3.0478 acc: 0.9411\n",
      "Epoch 2/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.4127 acc: 4.8752\n",
      "Validating...\n",
      "Val loss: 3.0471 acc: 1.1283\n",
      "Epoch 3/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.4771 acc: 5.4256\n",
      "Validating...\n",
      "Val loss: 3.0835 acc: 1.1248\n",
      "Epoch 4/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.5278 acc: 5.5456\n",
      "Validating...\n",
      "Val loss: 3.0969 acc: 1.1747\n",
      "Epoch 5/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.5664 acc: 5.5667\n",
      "Validating...\n",
      "Val loss: 3.1379 acc: 1.0019\n",
      "Epoch 6/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6009 acc: 5.4666\n",
      "Validating...\n",
      "Val loss: 3.1156 acc: 1.0934\n",
      "Epoch 7/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6187 acc: 5.4822\n",
      "Validating...\n",
      "Val loss: 3.1274 acc: 0.9965\n",
      "Epoch 8/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6364 acc: 5.3149\n",
      "Validating...\n",
      "Val loss: 3.1269 acc: 1.0150\n",
      "Epoch 9/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6484 acc: 5.2915\n",
      "Validating...\n",
      "Val loss: 3.1285 acc: 1.0650\n",
      "Epoch 10/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6573 acc: 5.2464\n",
      "Validating...\n",
      "Val loss: 3.1399 acc: 0.9862\n",
      "Epoch 11/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6624 acc: 5.0182\n",
      "Validating...\n",
      "Val loss: 3.1320 acc: 1.0515\n",
      "Epoch 12/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6658 acc: 4.9018\n",
      "Validating...\n",
      "Val loss: 3.1347 acc: 0.8675\n",
      "Epoch 13/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6675 acc: 4.8528\n",
      "Validating...\n",
      "Val loss: 3.1312 acc: 1.0358\n",
      "Epoch 14/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6679 acc: 4.8854\n",
      "Validating...\n",
      "Val loss: 3.1323 acc: 0.9987\n",
      "Epoch 15/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6701 acc: 4.8566\n",
      "Validating...\n",
      "Val loss: 3.1358 acc: 0.9094\n",
      "Epoch 16/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6687 acc: 4.9296\n",
      "Validating...\n",
      "Val loss: 3.1310 acc: 1.0608\n",
      "Epoch 17/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6694 acc: 4.8195\n",
      "Validating...\n",
      "Val loss: 3.1326 acc: 1.0624\n",
      "Epoch 18/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6710 acc: 4.7629\n",
      "Validating...\n",
      "Val loss: 3.1336 acc: 0.9546\n",
      "Epoch 19/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6720 acc: 4.7149\n",
      "Validating...\n",
      "Val loss: 3.1327 acc: 1.0074\n",
      "Epoch 20/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6721 acc: 4.6816\n",
      "Validating...\n",
      "Val loss: 3.1349 acc: 0.9110\n",
      "Epoch 21/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6738 acc: 4.5962\n",
      "Validating...\n",
      "Val loss: 3.1396 acc: 0.7974\n",
      "Epoch 22/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6744 acc: 4.6019\n",
      "Validating...\n",
      "Val loss: 3.1345 acc: 0.9197\n",
      "Epoch 23/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6749 acc: 4.5210\n",
      "Validating...\n",
      "Val loss: 3.1364 acc: 0.7968\n",
      "Epoch 24/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6752 acc: 4.6291\n",
      "Validating...\n",
      "Val loss: 3.1338 acc: 1.0118\n",
      "Epoch 25/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6739 acc: 4.6122\n",
      "Validating...\n",
      "Val loss: 3.1364 acc: 0.8435\n",
      "Epoch 26/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6740 acc: 4.6723\n",
      "Validating...\n",
      "Val loss: 3.1356 acc: 0.8624\n",
      "Epoch 27/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6737 acc: 4.6211\n",
      "Validating...\n",
      "Val loss: 3.1337 acc: 0.9504\n",
      "Epoch 28/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6753 acc: 4.5619\n",
      "Validating...\n",
      "Val loss: 3.1336 acc: 0.9971\n",
      "Epoch 29/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6748 acc: 4.6483\n",
      "Validating...\n",
      "Val loss: 3.1341 acc: 1.0141\n",
      "Epoch 30/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6750 acc: 4.5856\n",
      "Validating...\n",
      "Val loss: 3.1335 acc: 0.9904\n",
      "Epoch 31/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6755 acc: 4.5514\n",
      "Validating...\n",
      "Val loss: 3.1343 acc: 0.8842\n",
      "Epoch 32/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6749 acc: 4.5894\n",
      "Validating...\n",
      "Val loss: 3.1326 acc: 1.0570\n",
      "Epoch 33/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6747 acc: 4.5741\n",
      "Validating...\n",
      "Val loss: 3.1335 acc: 0.9395\n",
      "Epoch 34/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6746 acc: 4.6051\n",
      "Validating...\n",
      "Val loss: 3.1351 acc: 0.9280\n",
      "Epoch 35/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6738 acc: 4.7002\n",
      "Validating...\n",
      "Val loss: 3.1344 acc: 0.9485\n",
      "Epoch 36/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6743 acc: 4.6867\n",
      "Validating...\n",
      "Val loss: 3.1331 acc: 0.9690\n",
      "Epoch 37/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6738 acc: 4.6573\n",
      "Validating...\n",
      "Val loss: 3.1334 acc: 0.9770\n",
      "Epoch 38/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6732 acc: 4.7190\n",
      "Validating...\n",
      "Val loss: 3.1327 acc: 1.0106\n",
      "Epoch 39/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6739 acc: 4.6906\n",
      "Validating...\n",
      "Val loss: 3.1345 acc: 0.9142\n",
      "Epoch 40/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6731 acc: 4.6880\n",
      "Validating...\n",
      "Val loss: 3.1367 acc: 0.8054\n",
      "Epoch 41/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6738 acc: 4.6762\n",
      "Validating...\n",
      "Val loss: 3.1341 acc: 0.9654\n",
      "Epoch 42/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6742 acc: 4.6422\n",
      "Validating...\n",
      "Val loss: 3.1339 acc: 0.9014\n",
      "Epoch 43/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6743 acc: 4.6304\n",
      "Validating...\n",
      "Val loss: 3.1335 acc: 0.9395\n",
      "Epoch 44/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6740 acc: 4.6912\n",
      "Validating...\n",
      "Val loss: 3.1339 acc: 0.9795\n",
      "Epoch 45/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6739 acc: 4.6714\n",
      "Validating...\n",
      "Val loss: 3.1327 acc: 1.0230\n",
      "Epoch 46/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6734 acc: 4.7158\n",
      "Validating...\n",
      "Val loss: 3.1359 acc: 0.8486\n",
      "Epoch 47/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6736 acc: 4.6640\n",
      "Validating...\n",
      "Val loss: 3.1338 acc: 1.0131\n",
      "Epoch 48/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6740 acc: 4.6406\n",
      "Validating...\n",
      "Val loss: 3.1347 acc: 0.9581\n",
      "Epoch 49/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6724 acc: 4.7293\n",
      "Validating...\n",
      "Val loss: 3.1330 acc: 0.9773\n",
      "Epoch 50/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6729 acc: 4.7114\n",
      "Validating...\n",
      "Val loss: 3.1334 acc: 0.9898\n",
      "Epoch 51/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6730 acc: 4.6934\n",
      "Validating...\n",
      "Val loss: 3.1356 acc: 0.8813\n",
      "Epoch 52/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6729 acc: 4.7680\n",
      "Validating...\n",
      "Val loss: 3.1339 acc: 0.9894\n",
      "Epoch 53/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6732 acc: 4.6803\n",
      "Validating...\n",
      "Val loss: 3.1368 acc: 0.8106\n",
      "Epoch 54/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6740 acc: 4.6682\n",
      "Validating...\n",
      "Val loss: 3.1328 acc: 1.0410\n",
      "Epoch 55/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6726 acc: 4.6870\n",
      "Validating...\n",
      "Val loss: 3.1334 acc: 0.9459\n",
      "Epoch 56/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6737 acc: 4.6726\n",
      "Validating...\n",
      "Val loss: 3.1328 acc: 1.0550\n",
      "Epoch 57/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6729 acc: 4.7293\n",
      "Validating...\n",
      "Val loss: 3.1337 acc: 0.9952\n",
      "Epoch 58/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6719 acc: 4.7050\n",
      "Validating...\n",
      "Val loss: 3.1475 acc: 0.7741\n",
      "Epoch 59/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6721 acc: 4.6768\n",
      "Validating...\n",
      "Val loss: 3.1326 acc: 0.9878\n",
      "Epoch 60/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6729 acc: 4.6650\n",
      "Validating...\n",
      "Val loss: 3.1330 acc: 1.0131\n",
      "Epoch 61/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6733 acc: 4.6672\n",
      "Validating...\n",
      "Val loss: 3.1333 acc: 1.0003\n",
      "Epoch 62/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6726 acc: 4.7085\n",
      "Validating...\n",
      "Val loss: 3.1339 acc: 0.9347\n",
      "Epoch 63/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6743 acc: 4.6323\n",
      "Validating...\n",
      "Val loss: 3.1347 acc: 0.9424\n",
      "Epoch 64/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6746 acc: 4.6445\n",
      "Validating...\n",
      "Val loss: 3.1341 acc: 1.0106\n",
      "Epoch 65/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6738 acc: 4.6890\n",
      "Validating...\n",
      "Val loss: 3.1344 acc: 0.9238\n",
      "Epoch 66/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6734 acc: 4.6826\n",
      "Validating...\n",
      "Val loss: 3.1344 acc: 0.9421\n",
      "Epoch 67/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6733 acc: 4.7210\n",
      "Validating...\n",
      "Val loss: 3.1345 acc: 0.8816\n",
      "Epoch 68/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6737 acc: 4.7133\n",
      "Validating...\n",
      "Val loss: 3.1364 acc: 0.8227\n",
      "Epoch 69/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6734 acc: 4.6899\n",
      "Validating...\n",
      "Val loss: 3.1335 acc: 0.9779\n",
      "Epoch 70/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6741 acc: 4.6378\n",
      "Validating...\n",
      "Val loss: 3.1333 acc: 1.0042\n",
      "Epoch 71/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6729 acc: 4.6982\n",
      "Validating...\n",
      "Val loss: 3.1351 acc: 0.8992\n",
      "Epoch 72/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6739 acc: 4.6464\n",
      "Validating...\n",
      "Val loss: 3.1337 acc: 0.9546\n",
      "Epoch 73/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6734 acc: 4.6925\n",
      "Validating...\n",
      "Val loss: 3.1335 acc: 0.9802\n",
      "Epoch 74/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6729 acc: 4.6678\n",
      "Validating...\n",
      "Val loss: 3.1336 acc: 1.0214\n",
      "Epoch 75/99\n",
      "----------\n",
      "Training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 15.6730 acc: 4.7206\n",
      "Validating...\n",
      "Val loss: 3.1361 acc: 0.8173\n",
      "Epoch 76/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6726 acc: 4.7453\n",
      "Validating...\n",
      "Val loss: 3.1339 acc: 0.9712\n",
      "Epoch 77/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6732 acc: 4.6982\n",
      "Validating...\n",
      "Val loss: 3.1333 acc: 0.9494\n",
      "Epoch 78/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6730 acc: 4.7229\n",
      "Validating...\n",
      "Val loss: 3.1371 acc: 0.7830\n",
      "Epoch 79/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6736 acc: 4.6589\n",
      "Validating...\n",
      "Val loss: 3.1349 acc: 0.9517\n",
      "Epoch 80/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6743 acc: 4.6166\n",
      "Validating...\n",
      "Val loss: 3.1340 acc: 0.9392\n",
      "Epoch 81/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6748 acc: 4.6368\n",
      "Validating...\n",
      "Val loss: 3.1344 acc: 0.9472\n",
      "Epoch 82/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6738 acc: 4.6797\n",
      "Validating...\n",
      "Val loss: 3.1337 acc: 1.0163\n",
      "Epoch 83/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6734 acc: 4.6397\n",
      "Validating...\n",
      "Val loss: 3.1337 acc: 0.9795\n",
      "Epoch 84/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6727 acc: 4.7197\n",
      "Validating...\n",
      "Val loss: 3.1350 acc: 0.9101\n",
      "Epoch 85/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6730 acc: 4.7408\n",
      "Validating...\n",
      "Val loss: 3.1356 acc: 0.7850\n",
      "Epoch 86/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6742 acc: 4.6906\n",
      "Validating...\n",
      "Val loss: 3.1342 acc: 0.8819\n",
      "Epoch 87/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6733 acc: 4.7034\n",
      "Validating...\n",
      "Val loss: 3.1363 acc: 0.7814\n",
      "Epoch 88/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6736 acc: 4.6637\n",
      "Validating...\n",
      "Val loss: 3.1369 acc: 0.8109\n",
      "Epoch 89/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6728 acc: 4.7168\n",
      "Validating...\n",
      "Val loss: 3.1330 acc: 0.9802\n",
      "Epoch 90/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6735 acc: 4.6621\n",
      "Validating...\n",
      "Val loss: 3.1352 acc: 0.8813\n",
      "Epoch 91/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6742 acc: 4.6992\n",
      "Validating...\n",
      "Val loss: 3.1335 acc: 0.9901\n",
      "Epoch 92/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6743 acc: 4.6128\n",
      "Validating...\n",
      "Val loss: 3.1339 acc: 1.0154\n",
      "Epoch 93/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6742 acc: 4.6592\n",
      "Validating...\n",
      "Val loss: 3.1376 acc: 0.7965\n",
      "Epoch 94/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6738 acc: 4.6752\n",
      "Validating...\n",
      "Val loss: 3.1333 acc: 0.9741\n",
      "Epoch 95/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6745 acc: 4.6752\n",
      "Validating...\n",
      "Val loss: 3.1346 acc: 0.9334\n",
      "Epoch 96/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6740 acc: 4.6595\n",
      "Validating...\n",
      "Val loss: 3.1341 acc: 1.0192\n",
      "Epoch 97/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6732 acc: 4.7043\n",
      "Validating...\n",
      "Val loss: 3.1342 acc: 1.0019\n",
      "Epoch 98/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6738 acc: 4.6883\n",
      "Validating...\n",
      "Val loss: 3.1333 acc: 0.9725\n",
      "Epoch 99/99\n",
      "----------\n",
      "Training...\n",
      "Train loss: 15.6737 acc: 4.6835\n",
      "Validating...\n",
      "Val loss: 3.1365 acc: 0.7843\n",
      "Training complete in 130m 4s\n",
      "Best val Acc: 1.174720\n",
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n",
      "Waiting for the remaining 1 operations to synchronize with Neptune. Do not kill this process.\n",
      "All 1 operations synced, thanks for waiting!\n",
      "Explore the metadata in the Neptune app:\n",
      "https://app.neptune.ai/mohan20325145/resnet/e/RESNETNEP-169\n"
     ]
    }
   ],
   "source": [
    "#Data loader\n",
    "trainset, testset = load_data(data_dir)\n",
    "\n",
    "#Tune model params\n",
    "if tune_hyperparams == True:\n",
    "    l1, l2, lr, batch_size = tune_model() \n",
    "else:\n",
    "    l1 = 16\n",
    "    l2 = 8\n",
    "    lr = 1e-3\n",
    "    batch_size = 16 #16\n",
    "\n",
    "#Train model\n",
    "if train_network == True:\n",
    "    train_model()\n",
    "\n",
    "#Test model\n",
    "if test_network == True:\n",
    "    test_model()\n",
    "\n",
    "#Logging\n",
    "logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#         train_accuracy.update(predicted, labels)\n",
    "#         epoch_accuracy = train_accuracy.compute()\n",
    "#         train_accuracy.reset() \n",
    "#         predicted = predicted.cpu().detach().numpy()\n",
    "#         labels = labels.cpu().detach().numpy()\n",
    "#         epoch_accuracy_score = accuracy_score(labels, predicted)\n",
    "#         epoch_precision_score = precision_score(labels, predicted, average='weighted')\n",
    "#         epoch_f1_score = f1_score(labels, predicted, average='weighted')\n",
    "#         epoch_recall_score = recall_score(labels, predicted, average='weighted')\n",
    "#         nep_logger['plots/training/accuracy_sklearn'+ str(training_config)].log(epoch_accuracy_score)\n",
    "#         nep_logger['plots/training/precision_score'+ str(training_config)].log(epoch_precision_score)\n",
    "#         nep_logger['plots/training/f1_score'+ str(training_config)].log(epoch_f1_score)\n",
    "#         nep_logger['plots/training/recall_score'+ str(training_config)].log(epoch_recall_score)\n",
    "#         tnsr_board_logger.add_scalar('plots/training/loss'+ str(training_config), epoch_loss, epoch)\n",
    "#             fig, axis = plt.subplots(figsize = (20,20))\n",
    "#             plot_confusion_matrix(labels, predicted, ax=axis, normalize=True)\n",
    "#             ticks = np.arange(class_len)\n",
    "#             plt.xticks(ticks, classes, rotation=0, fontsize=14)\n",
    "#             plt.yticks(ticks, classes, fontsize=14)\n",
    "#             plt.title('Confusion Matrix', fontsize=20)\n",
    "#             nep_logger[\"images/training/conf_matrix\"].upload(fig)       \n",
    "#         PATH = './cifar_net_' + str(training_count) + '.pth'\n",
    "#         torch.save(net.state_dict(), PATH)\n",
    "    \n",
    "    \n",
    "#                 match = torch.reshape(torch.eq(predicted, labels).float(), (-1, 1))\n",
    "#                 acc = torch.mean(match)\n",
    "#                 evidence = relu_evidence(outputs)    \n",
    "#                 alpha = evidence + 1\n",
    "#                 u = class_len / torch.sum(alpha, dim=1, keepdim=True)\n",
    "#                 total_evidence = torch.sum(evidence, 1, keepdim=True)\n",
    "#                 mean_evidence = torch.mean(total_evidence)\n",
    "#                 mean_evidence_succ = torch.sum(torch.sum(evidence, 1, keepdim=True) * match) / torch.sum(match + 1e-20)\n",
    "#                 mean_evidence_fail = torch.sum(torch.sum(evidence, 1, keepdim=True) * (1 - match)) / (torch.sum(torch.abs(1 - match)) + 1e-20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
