{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchmetrics in /opt/conda/lib/python3.9/site-packages (0.11.0)\n",
      "Requirement already satisfied: torch>=1.8.1 in /opt/conda/lib/python3.9/site-packages (from torchmetrics) (1.11.0+cu113)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.9/site-packages (from torchmetrics) (1.22.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from torchmetrics) (21.3)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torch>=1.8.1->torchmetrics) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging->torchmetrics) (3.0.9)\n",
      "Requirement already satisfied: neptune-client in /opt/conda/lib/python3.9/site-packages (0.16.14)\n",
      "Requirement already satisfied: swagger-spec-validator>=2.7.4 in /opt/conda/lib/python3.9/site-packages (from neptune-client) (3.0.3)\n",
      "Requirement already satisfied: boto3>=1.16.0 in /opt/conda/lib/python3.9/site-packages (from neptune-client) (1.26.27)\n",
      "Requirement already satisfied: GitPython>=2.0.8 in /opt/conda/lib/python3.9/site-packages (from neptune-client) (3.1.29)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from neptune-client) (21.3)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.9/site-packages (from neptune-client) (1.26.11)\n",
      "Requirement already satisfied: PyJWT in /opt/conda/lib/python3.9/site-packages (from neptune-client) (2.4.0)\n",
      "Requirement already satisfied: future>=0.17.1 in /opt/conda/lib/python3.9/site-packages (from neptune-client) (0.18.2)\n",
      "Requirement already satisfied: oauthlib>=2.1.0 in /opt/conda/lib/python3.9/site-packages (from neptune-client) (3.2.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.9/site-packages (from neptune-client) (5.9.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from neptune-client) (1.4.3)\n",
      "Requirement already satisfied: requests-oauthlib>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from neptune-client) (1.3.1)\n",
      "Requirement already satisfied: bravado<12.0.0,>=11.0.0 in /opt/conda/lib/python3.9/site-packages (from neptune-client) (11.0.3)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.9/site-packages (from neptune-client) (8.0.4)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.9/site-packages (from neptune-client) (1.16.0)\n",
      "Requirement already satisfied: websocket-client!=1.0.0,>=0.35.0 in /opt/conda/lib/python3.9/site-packages (from neptune-client) (1.3.3)\n",
      "Requirement already satisfied: Pillow>=1.1.6 in /opt/conda/lib/python3.9/site-packages (from neptune-client) (9.2.0)\n",
      "Requirement already satisfied: requests>=2.20.0 in /opt/conda/lib/python3.9/site-packages (from neptune-client) (2.28.1)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.9/site-packages (from boto3>=1.16.0->neptune-client) (1.0.1)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.27 in /opt/conda/lib/python3.9/site-packages (from boto3>=1.16.0->neptune-client) (1.29.27)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.9/site-packages (from boto3>=1.16.0->neptune-client) (0.6.0)\n",
      "Requirement already satisfied: bravado-core>=5.16.1 in /opt/conda/lib/python3.9/site-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (5.17.1)\n",
      "Requirement already satisfied: msgpack in /opt/conda/lib/python3.9/site-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (1.0.4)\n",
      "Requirement already satisfied: monotonic in /opt/conda/lib/python3.9/site-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (1.6)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.9/site-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (6.0)\n",
      "Requirement already satisfied: simplejson in /opt/conda/lib/python3.9/site-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (3.18.0)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.9/site-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (4.3.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.9/site-packages (from GitPython>=2.0.8->neptune-client) (4.0.10)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests>=2.20.0->neptune-client) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.9/site-packages (from requests>=2.20.0->neptune-client) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests>=2.20.0->neptune-client) (2022.6.15)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.9/site-packages (from swagger-spec-validator>=2.7.4->neptune-client) (4.9.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging->neptune-client) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas->neptune-client) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.9/site-packages (from pandas->neptune-client) (1.22.4)\n",
      "Requirement already satisfied: jsonref in /opt/conda/lib/python3.9/site-packages (from bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client) (1.0.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->GitPython>=2.0.8->neptune-client) (5.0.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.9/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (22.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.9/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (0.18.1)\n",
      "Requirement already satisfied: fqdn in /opt/conda/lib/python3.9/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (1.5.1)\n",
      "Requirement already satisfied: webcolors>=1.11 in /opt/conda/lib/python3.9/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (1.12)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /opt/conda/lib/python3.9/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (2.3)\n",
      "Requirement already satisfied: isoduration in /opt/conda/lib/python3.9/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (20.11.0)\n",
      "Requirement already satisfied: uri-template in /opt/conda/lib/python3.9/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (1.2.0)\n",
      "Requirement already satisfied: rfc3339-validator in /opt/conda/lib/python3.9/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (0.1.4)\n",
      "Requirement already satisfied: rfc3987 in /opt/conda/lib/python3.9/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (1.3.8)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /opt/conda/lib/python3.9/site-packages (from isoduration->jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (1.2.3)\n",
      "Requirement already satisfied: scikit-plot in /opt/conda/lib/python3.9/site-packages (0.3.7)\n",
      "Requirement already satisfied: matplotlib>=1.4.0 in /opt/conda/lib/python3.9/site-packages (from scikit-plot) (3.5.2)\n",
      "Requirement already satisfied: joblib>=0.10 in /opt/conda/lib/python3.9/site-packages (from scikit-plot) (1.1.0)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /opt/conda/lib/python3.9/site-packages (from scikit-plot) (1.1.2)\n",
      "Requirement already satisfied: scipy>=0.9 in /opt/conda/lib/python3.9/site-packages (from scikit-plot) (1.8.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=1.4.0->scikit-plot) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=1.4.0->scikit-plot) (4.34.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=1.4.0->scikit-plot) (1.22.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=1.4.0->scikit-plot) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=1.4.0->scikit-plot) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=1.4.0->scikit-plot) (9.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=1.4.0->scikit-plot) (0.11.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn>=0.18->scikit-plot) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=1.4.0->scikit-plot) (1.16.0)\n",
      "Requirement already satisfied: ray[tune] in /opt/conda/lib/python3.9/site-packages (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /opt/conda/lib/python3.9/site-packages (from ray[tune]) (1.22.4)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.9/site-packages (from ray[tune]) (6.0)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.9/site-packages (from ray[tune]) (4.9.1)\n",
      "Requirement already satisfied: frozenlist in /opt/conda/lib/python3.9/site-packages (from ray[tune]) (1.3.3)\n",
      "Requirement already satisfied: virtualenv>=20.0.24 in /opt/conda/lib/python3.9/site-packages (from ray[tune]) (20.17.1)\n",
      "Requirement already satisfied: attrs in /opt/conda/lib/python3.9/site-packages (from ray[tune]) (22.1.0)\n",
      "Requirement already satisfied: grpcio>=1.32.0 in /opt/conda/lib/python3.9/site-packages (from ray[tune]) (1.47.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from ray[tune]) (2.28.1)\n",
      "Requirement already satisfied: click<=8.0.4,>=7.0 in /opt/conda/lib/python3.9/site-packages (from ray[tune]) (8.0.4)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /opt/conda/lib/python3.9/site-packages (from ray[tune]) (3.20.1)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from ray[tune]) (1.0.4)\n",
      "Requirement already satisfied: aiosignal in /opt/conda/lib/python3.9/site-packages (from ray[tune]) (1.3.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from ray[tune]) (3.8.2)\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.9/site-packages (from ray[tune]) (0.9.0)\n",
      "Requirement already satisfied: tensorboardX>=1.9 in /opt/conda/lib/python3.9/site-packages (from ray[tune]) (2.5.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from ray[tune]) (1.4.3)\n",
      "Requirement already satisfied: six>=1.5.2 in /opt/conda/lib/python3.9/site-packages (from grpcio>=1.32.0->ray[tune]) (1.16.0)\n",
      "Requirement already satisfied: platformdirs<3,>=2.4 in /opt/conda/lib/python3.9/site-packages (from virtualenv>=20.0.24->ray[tune]) (2.6.0)\n",
      "Requirement already satisfied: distlib<1,>=0.3.6 in /opt/conda/lib/python3.9/site-packages (from virtualenv>=20.0.24->ray[tune]) (0.3.6)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.9/site-packages (from jsonschema->ray[tune]) (0.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.9/site-packages (from pandas->ray[tune]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas->ray[tune]) (2022.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.9/site-packages (from requests->ray[tune]) (2.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->ray[tune]) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->ray[tune]) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->ray[tune]) (2022.6.15)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchmetrics\n",
    "!pip install neptune-client\n",
    "!pip install scikit-plot\n",
    "!pip install -U \"ray[tune]\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split\n",
    "from torchmetrics import Accuracy\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.models import resnet18,mobilenet_v2\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import glob\n",
    "import seaborn as sn\n",
    "from functools import partial\n",
    "import scipy.ndimage as nd\n",
    "import neptune.new as neptune\n",
    "from sklearn.metrics import confusion_matrix ,classification_report,accuracy_score,f1_score,precision_score,recall_score\n",
    "from scikitplot.metrics import plot_confusion_matrix\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13299/1891364469.py:12: NeptuneDeprecationWarning: `init` is deprecated, use `init_run` instead. We'll end support of it in `neptune-client==1.0.0`.\n",
      "  nep_logger = neptune.init(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/mohan20325145/resnet/e/RESNETNEP-155\n",
      "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    }
   ],
   "source": [
    "#General\n",
    "data_dir = os.path.abspath(\"./data\")\n",
    "classes  = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "class_len = len(classes)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "training_config  = 0\n",
    "train_accuracy = Accuracy(task=\"multiclass\", num_classes = class_len)\n",
    "train_accuracy.to(device)\n",
    "l1 = l2 = lr = batch_size = 0\n",
    "\n",
    "tnsr_board_logger = SummaryWriter()\n",
    "nep_logger = neptune.init(\n",
    "project=\"mohan20325145/resnet\",\n",
    "api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJhZWQyMTU4OC02NmU4LTRiNjgtYWE5Zi1lNDg5MjdmZGJhNzYifQ==\",)\n",
    "\n",
    "\n",
    "#Tuning \n",
    "tune_hyperparams = False\n",
    "num_samples = 4\n",
    "max_num_epochs = 3\n",
    "gpus_per_trial = 0 \n",
    "\n",
    "\n",
    "#Training\n",
    "num_workers = 2\n",
    "epochs = [10]\n",
    "optimizer = [\"Adam\"]\n",
    "criterion = [nn.CrossEntropyLoss()]\n",
    "model = [\"ResNet\"]\n",
    "save_model_params = True\n",
    "\n",
    "#num_workers = [2,3]\n",
    "#criterion = [\"Evidential\", nn.CrossEntropyLoss(), nn.NLLLoss(), nn.GaussianNLLLoss(), nn.SoftMarginLoss()] \n",
    "#optimizer = [\"Adam\", \"SGD\", \"ASGD\", \"Adamax\"]\n",
    "#epochs = [40, 100]\n",
    "#model = [\"ResNet\", \"MobileNet\", \"CustomNet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir):\n",
    "    transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    trainset = torchvision.datasets.CIFAR10(root=data_dir, train=True, download=True, transform=transform)\n",
    "    testset = torchvision.datasets.CIFAR10(root=data_dir, train=False, download=True, transform=transform)\n",
    "    return trainset, testset\n",
    "\n",
    "def logger():\n",
    "    nep_logger.stop()\n",
    "    tnsr_board_logger.close\n",
    "    # !tensorboard --logdir=runs\n",
    "\n",
    "class Param_Tuning_NN(nn.Module):\n",
    "    def __init__(self, l1, l2):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, l1)\n",
    "        self.fc2 = nn.Linear(l1, l2)\n",
    "        self.fc3 = nn.Linear(l2, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)   \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x  \n",
    "    \n",
    "class Custom_Train_NN(nn.Module):\n",
    "    def __init__(self, l1, l2):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, l1)\n",
    "        self.fc2 = nn.Linear(l1, l2)\n",
    "        self.fc3 = nn.Linear(l2, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x,1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_subroutine(config, checkpoint_dir=None, data_dir=None):\n",
    "    \n",
    "    net = Param_Tuning_NN(config[\"l1\"], config[\"l2\"])\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            net = nn.DataParallel(net)\n",
    "    net.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=config[\"lr\"], momentum=0.9)\n",
    "\n",
    "    if checkpoint_dir:\n",
    "        model_state, optimizer_state = torch.load(os.path.join(checkpoint_dir, \"checkpoint\"))\n",
    "        net.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "        \n",
    "    trainset, testset = load_data(data_dir)\n",
    "    test_abs = int(len(trainset) * 0.8)\n",
    "    train_subset, val_subset = random_split(trainset, [test_abs, len(trainset) - test_abs])\n",
    "    trainloader = torch.utils.data.DataLoader(train_subset, batch_size=int(config[\"batch_size\"]), shuffle=True, num_workers=8)\n",
    "    valloader = torch.utils.data.DataLoader(val_subset, batch_size=int(config[\"batch_size\"]), shuffle=True, num_workers=8)\n",
    "\n",
    "    for epoch in range(10):\n",
    "        running_loss = 0.0\n",
    "        epoch_steps = 0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        val_loss = 0.0\n",
    "        val_steps = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for i, data in enumerate(valloader, 0):\n",
    "            with torch.no_grad():\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = net(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.cpu().numpy()\n",
    "                val_steps += 1\n",
    "        with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
    "            path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "            torch.save((net.state_dict(), optimizer.state_dict()), path)\n",
    "        tune.report(loss=(val_loss / val_steps), accuracy=correct / total)\n",
    "    \n",
    "    \n",
    "def tune_model():\n",
    "    config = {\"l1\": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),\n",
    "              \"l2\": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),\n",
    "              \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "              \"batch_size\": tune.choice([2, 4, 8, 16])}\n",
    "    scheduler = ASHAScheduler(metric=\"loss\",\n",
    "                              mode=\"min\",\n",
    "                              max_t=max_num_epochs,\n",
    "                              grace_period=1,\n",
    "                              reduction_factor=2)\n",
    "    reporter = CLIReporter(metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n",
    "    result = tune.run(partial(tune_subroutine, data_dir=data_dir),\n",
    "             resources_per_trial={\"cpu\": 2, \"gpu\": gpus_per_trial},\n",
    "             config=config,\n",
    "             num_samples=num_samples,\n",
    "             scheduler=scheduler,\n",
    "             progress_reporter=reporter)\n",
    "\n",
    "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "    print(\"Best trial config: {}\".format(best_trial.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(best_trial.last_result[\"loss\"]))\n",
    "    print(\"Best trial final validation accuracy: {}\".format(best_trial.last_result[\"accuracy\"]))\n",
    "    return best_trial.config['l1'], best_trial.config['l2'], best_trial.config['lr'], best_trial.config['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_embedding(labels, num_classes):\n",
    "    y = torch.eye(num_classes)\n",
    "    return y[labels]\n",
    "\n",
    "def relu_evidence(y):\n",
    "    return F.relu(y)\n",
    "\n",
    "def kl_divergence(alpha, num_classes, device=None):\n",
    "    beta = torch.ones([1, num_classes], dtype=torch.float32, device=device)\n",
    "    S_alpha = torch.sum(alpha, dim=1, keepdim=True)\n",
    "    S_beta = torch.sum(beta, dim=1, keepdim=True)\n",
    "    lnB = torch.lgamma(S_alpha) - torch.sum(torch.lgamma(alpha), dim=1, keepdim=True)\n",
    "    lnB_uni = torch.sum(torch.lgamma(beta), dim=1, keepdim=True) - torch.lgamma(S_beta)\n",
    "    dg0 = torch.digamma(S_alpha)\n",
    "    dg1 = torch.digamma(alpha)\n",
    "    kl = torch.sum((alpha - beta) * (dg1 - dg0), dim=1, keepdim=True) + lnB + lnB_uni\n",
    "    return kl\n",
    "\n",
    "def loglikelihood_loss(y, alpha, device=None):\n",
    "    y = y.to(device)\n",
    "    alpha = alpha.to(device)\n",
    "    S = torch.sum(alpha, dim=1, keepdim=True)\n",
    "    loglikelihood_err = torch.sum((y - (alpha / S)) ** 2, dim=1, keepdim=True)\n",
    "    loglikelihood_var = torch.sum(alpha * (S - alpha) / (S * S * (S + 1)), dim=1, keepdim=True)\n",
    "    loglikelihood = loglikelihood_err + loglikelihood_var\n",
    "    return loglikelihood\n",
    "\n",
    "def mse_loss(y, alpha, epoch_num, num_classes, annealing_step, device=None):\n",
    "    y = y.to(device)\n",
    "    alpha = alpha.to(device)\n",
    "    loglikelihood = loglikelihood_loss(y, alpha, device=device)\n",
    "    annealing_coef = torch.min(torch.tensor(1.0, dtype=torch.float32), torch.tensor(epoch_num / annealing_step, dtype=torch.float32))\n",
    "    kl_alpha = (alpha - 1) * (1 - y) + 1\n",
    "    kl_div = annealing_coef * kl_divergence(kl_alpha, num_classes, device=device)\n",
    "    return loglikelihood + kl_div\n",
    "\n",
    "def edl_mse_loss(output, target, epoch_num, num_classes, annealing_step, device=None):\n",
    "    evidence = relu_evidence(output)\n",
    "    alpha = evidence + 1\n",
    "    loss = torch.mean(mse_loss(target, alpha, epoch_num, num_classes, annealing_step, device=device))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_subroutine(criterion_, optimizer_, epochs_, model_):\n",
    "    nep_logger['params/training/model'+ str(training_config)].log(model_)\n",
    "    nep_logger['params/training/model'+ str(training_config)].log(criterion_)\n",
    "    nep_logger['params/training/model'+ str(training_config)].log(epochs_)\n",
    "    nep_logger['params/training/model'+ str(training_config)].log(optimizer_)\n",
    "    \n",
    "    if (model_ == \"ResNet\"):\n",
    "        net = resnet18()\n",
    "        net.fc = nn.Linear(in_features=512,out_features=class_len)\n",
    "    elif (model_ == \"MobileNet\"):\n",
    "        net = mobilenet_v2()\n",
    "        net.fc = nn.Linear(in_features=512,out_features=class_len)\n",
    "    elif (model_ == \"CustomNet\"):\n",
    "        net = Custom_Train_NN(l1, l2)   \n",
    "\n",
    "    if (optimizer_ == \"Adam\"):\n",
    "        optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=0.005)\n",
    "    elif (optimizer_ == \"SGD\"):\n",
    "        optimizer = optim.SGD(net.parameters(), lr=lr)\n",
    "   \n",
    "    net = net.to(device)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    for epoch in range(epochs_):\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            _,predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            \n",
    "            if criterion_ == \"Evidential\":\n",
    "                y = one_hot_embedding(labels=labels,num_classes=class_len)\n",
    "                y.to(device)\n",
    "                loss = edl_mse_loss(outputs, y.float(), epoch, class_len, 10, device)\n",
    "            else:\n",
    "                loss = criterion_(outputs, labels)\n",
    "                \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()* inputs.size(0)\n",
    "            running_corrects += torch.sum(predicted == labels.data)\n",
    "            \n",
    "        epoch_loss = running_loss / len(trainloader)\n",
    "        epoch_acc = running_corrects.double() / len(trainloader)\n",
    "        nep_logger['plots/training/loss'+ str(training_config)].log(epoch_loss)\n",
    "        nep_logger['plots/training/accuracy'+ str(training_config)].log(epoch_acc.item())\n",
    "    if save_model_params:\n",
    "        state = {\"epoch\": epochs_,\n",
    "                 \"model_state_dict\": net.state_dict(),\n",
    "                 \"optimizer_state_dict\": optimizer.state_dict()}\n",
    "        torch.save(state, \"./results/model.pt\")\n",
    "    \n",
    "\n",
    "def train_model():\n",
    "    global training_config\n",
    "    for loss, opti, epo, mod in [(loss, opti, epo, mod) for loss in criterion for opti in optimizer for epo in epochs for mod in model]:\n",
    "        training_config += 1\n",
    "        train_model_subroutine(loss, opti, epo, mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n",
      "Waiting for the remaining 3 operations to synchronize with Neptune. Do not kill this process.\n",
      "All 3 operations synced, thanks for waiting!\n",
      "Explore the metadata in the Neptune app:\n",
      "https://app.neptune.ai/mohan20325145/resnet/e/RESNETNEP-155\n"
     ]
    }
   ],
   "source": [
    "#Data loader\n",
    "trainset, testset = load_data(data_dir)\n",
    "\n",
    "#Tune model params\n",
    "if tune_hyperparams == True:\n",
    "    l1, l2, lr, batch_size = tune_model() \n",
    "else:\n",
    "    l1 = 16\n",
    "    l2 = 8\n",
    "    lr = 1e-3\n",
    "    batch_size = 16\n",
    "\n",
    "#Train model\n",
    "model = train_model()\n",
    "\n",
    "#Logging\n",
    "logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#         train_accuracy.update(predicted, labels)\n",
    "#         epoch_accuracy = train_accuracy.compute()\n",
    "#         train_accuracy.reset() \n",
    "#         predicted = predicted.cpu().detach().numpy()\n",
    "#         labels = labels.cpu().detach().numpy()\n",
    "#         epoch_accuracy_score = accuracy_score(labels, predicted)\n",
    "#         epoch_precision_score = precision_score(labels, predicted, average='weighted')\n",
    "#         epoch_f1_score = f1_score(labels, predicted, average='weighted')\n",
    "#         epoch_recall_score = recall_score(labels, predicted, average='weighted')\n",
    "#         nep_logger['plots/training/accuracy_sklearn'+ str(training_config)].log(epoch_accuracy_score)\n",
    "#         nep_logger['plots/training/precision_score'+ str(training_config)].log(epoch_precision_score)\n",
    "#         nep_logger['plots/training/f1_score'+ str(training_config)].log(epoch_f1_score)\n",
    "#         nep_logger['plots/training/recall_score'+ str(training_config)].log(epoch_recall_score)\n",
    "#         tnsr_board_logger.add_scalar('plots/training/loss'+ str(training_config), epoch_loss, epoch)\n",
    "#             fig, axis = plt.subplots(figsize = (20,20))\n",
    "#             plot_confusion_matrix(labels, predicted, ax=axis, normalize=True)\n",
    "#             ticks = np.arange(class_len)\n",
    "#             plt.xticks(ticks, classes, rotation=0, fontsize=14)\n",
    "#             plt.yticks(ticks, classes, fontsize=14)\n",
    "#             plt.title('Confusion Matrix', fontsize=20)\n",
    "#             nep_logger[\"images/training/conf_matrix\"].upload(fig)       \n",
    "#         PATH = './cifar_net_' + str(training_count) + '.pth'\n",
    "#         torch.save(net.state_dict(), PATH)\n",
    "    \n",
    "    \n",
    "#                 match = torch.reshape(torch.eq(predicted, labels).float(), (-1, 1))\n",
    "#                 acc = torch.mean(match)\n",
    "#                 evidence = relu_evidence(outputs)    \n",
    "#                 alpha = evidence + 1\n",
    "#                 u = class_len / torch.sum(alpha, dim=1, keepdim=True)\n",
    "#                 total_evidence = torch.sum(evidence, 1, keepdim=True)\n",
    "#                 mean_evidence = torch.mean(total_evidence)\n",
    "#                 mean_evidence_succ = torch.sum(torch.sum(evidence, 1, keepdim=True) * match) / torch.sum(match + 1e-20)\n",
    "#                 mean_evidence_fail = torch.sum(torch.sum(evidence, 1, keepdim=True) * (1 - match)) / (torch.sum(torch.abs(1 - match)) + 1e-20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
