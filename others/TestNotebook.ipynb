{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch import nn\n",
    "# import blobconverter\n",
    "# from onnxsim import simplify\n",
    "# import onnx\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# class Model(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Model, self).__init__()\n",
    "#         self.fc1 = nn.Linear(4, 100)\n",
    "#         self.fc2 = nn.Linear(100, 100)\n",
    "#         self.fc3 = nn.Linear(100, 3)\n",
    "#         self.softmax = nn.Softmax(dim=1) \n",
    "\n",
    "#     def forward(self, X):\n",
    "#         X = F.relu(self.fc1(X))\n",
    "#         X = self.fc2(X)\n",
    "#         X = self.fc3(X)\n",
    "#         return X\n",
    "\n",
    "\n",
    "\n",
    "# model = Model()\n",
    "# shape = (10,4)\n",
    "# X = torch.ones(shape, dtype=torch.float32)\n",
    "\n",
    "# onnx_file = \"../../results/test.onnx\"\n",
    "# torch.onnx.export(\n",
    "#     model,\n",
    "#     X,\n",
    "#     onnx_file,\n",
    "#     opset_version=12,\n",
    "#     do_constant_folding=True,\n",
    "# )\n",
    "\n",
    "\n",
    "# onnx_simplified_path = \"../../results/onnx_simple.onnx\"\n",
    "# onnx_model =  onnx.load(onnx_file)\n",
    "# model_simp, check = simplify(onnx_model)\n",
    "# onnx.save(model_simp, onnx_simplified_path)\n",
    "\n",
    "\n",
    "# blobconverter.from_onnx(\n",
    "#     model=onnx_file,\n",
    "#     data_type=\"FP16\",\n",
    "#     shaves=6,\n",
    "#     use_cache=False,\n",
    "#     output_dir=\"../../results\",\n",
    "#     optimizer_params=[]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Downloading ../../results/test_openvino_2021.4_8shave.blob...\n",
      "[==========================                        ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import blobconverter\n",
    "from onnxsim import simplify\n",
    "import onnx\n",
    "\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models import resnet18,mobilenet_v2,ResNet18_Weights\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import MobileNetV2\n",
    "\n",
    "data_dir = os.path.abspath(\"../../data\")\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), transforms.RandomErasing()])\n",
    "trainset = torchvision.datasets.CIFAR10(root=data_dir, train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "dataiter = iter(trainloader) \n",
    "images, labels = next(dataiter)\n",
    "\n",
    "model = resnet18(weights = ResNet18_Weights.DEFAULT)\n",
    "model.fc = nn.Linear(in_features=512,out_features=10)\n",
    "model.load_state_dict(torch.load(\"../../results/Crossentropy_Resnet18_model.pth\"))  \n",
    "\n",
    "\n",
    "shape = (10,4)\n",
    "X = torch.ones(shape, dtype=torch.float32)\n",
    "\n",
    "onnx_file = \"../../results/test.onnx\"\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    images,\n",
    "    onnx_file,\n",
    "    opset_version=12,\n",
    "    do_constant_folding=True,\n",
    ")\n",
    "\n",
    "\n",
    "onnx_simplified_path = \"../../results/onnx_simple.onnx\"\n",
    "onnx_model =  onnx.load(onnx_file)\n",
    "model_simp, check = simplify(onnx_model)\n",
    "onnx.save(model_simp, onnx_simplified_path)\n",
    "\n",
    "\n",
    "blobconverter.from_onnx(\n",
    "    model=onnx_file,\n",
    "    data_type=\"FP16\",\n",
    "    shaves=8,\n",
    "    use_cache=False,\n",
    "    output_dir=\"../../results\",\n",
    "    optimizer_params=[]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rnd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f7e8fdd6c7089b66554fb6a2fb9ba4ef5dc66a5cacc103223d0f5e702d5f7a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
