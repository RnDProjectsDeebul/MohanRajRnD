{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-28 21:13:16.805218: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-28 21:13:17.571632: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/slurm/slurm-19.05.5/lib:/usr/local/slurm/slurm-19.05.5/lib/slurm:/usr/local/lib:\n",
      "2023-02-28 21:13:17.571734: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/slurm/slurm-19.05.5/lib:/usr/local/slurm/slurm-19.05.5/lib/slurm:/usr/local/lib:\n",
      "2023-02-28 21:13:17.571745: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import onnx\n",
    "import torch.nn.functional as F\n",
    "from onnx_tf.backend import prepare\n",
    "import tensorflow as tf\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 100)\n",
    "        self.fc2 = nn.Linear(100, 100)\n",
    "        self.fc3 = nn.Linear(100, 3)\n",
    "        self.softmax = nn.Softmax(dim=1) \n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = self.fc2(X)\n",
    "        X = self.fc3(X)\n",
    "        return X\n",
    "\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-28 21:13:19.153408: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-02-28 21:13:19.153479: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (wr0): /proc/driver/nvidia/version does not exist\n",
      "2023-02-28 21:13:19.154217: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:absl:Function `__call__` contains input name(s) onnx_tf__tf_Gemm_0_7549e7ac with unsupported characters which will be renamed to onnx_tf__tf_gemm_0_7549e7ac in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../results/Coral_iris_model.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../results/Coral_iris_model.tf/assets\n"
     ]
    }
   ],
   "source": [
    "onnx_file = \"../../results/Coral_iris_model.onnx\"\n",
    "tf_model_path = \"../../results/Coral_iris_model.tf\"\n",
    "\n",
    "\n",
    "shape = (10,4)\n",
    "X = torch.ones(shape, dtype=torch.float32)\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    X,\n",
    "    onnx_file,\n",
    "    opset_version=12,\n",
    "    do_constant_folding=True,\n",
    ")\n",
    "\n",
    "onnx_model =  onnx.load(onnx_file)\n",
    "tf_rep = prepare(onnx_model)\n",
    "tf_rep.export_graph(tf_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m converter\u001b[39m.\u001b[39minference_input_type \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39muint8\n\u001b[1;32m     10\u001b[0m converter\u001b[39m.\u001b[39minference_output_type \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39muint8\n\u001b[0;32m---> 13\u001b[0m tflite_model \u001b[39m=\u001b[39m converter\u001b[39m.\u001b[39;49mconvert()\n\u001b[1;32m     14\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(tflite_model_path, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f: \n\u001b[1;32m     15\u001b[0m     f\u001b[39m.\u001b[39mwrite(tflite_model)\n",
      "File \u001b[0;32m~/anaconda3/envs/rnd/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:933\u001b[0m, in \u001b[0;36m_export_metrics.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(convert_func)\n\u001b[1;32m    931\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    932\u001b[0m   \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_convert_and_export_metrics(convert_func, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/rnd/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:909\u001b[0m, in \u001b[0;36mTFLiteConverterBase._convert_and_export_metrics\u001b[0;34m(self, convert_func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wraps around convert function to export metrics.\u001b[39;00m\n\u001b[1;32m    899\u001b[0m \n\u001b[1;32m    900\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[39m  The decorator to wrap the convert function.\u001b[39;00m\n\u001b[1;32m    907\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    908\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_increase_conversion_attempt_metric()\n\u001b[0;32m--> 909\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save_conversion_params_metric()\n\u001b[1;32m    910\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mprocess_time()\n\u001b[1;32m    911\u001b[0m result \u001b[39m=\u001b[39m convert_func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/rnd/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:768\u001b[0m, in \u001b[0;36mTFLiteConverterBase._save_conversion_params_metric\u001b[0;34m(self, graph_def, inference_type, inference_input_type)\u001b[0m\n\u001b[1;32m    765\u001b[0m converter_kwargs\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_base_converter_args())\n\u001b[1;32m    767\u001b[0m \u001b[39m# Optimization parameters.\u001b[39;00m\n\u001b[0;32m--> 768\u001b[0m quant_mode \u001b[39m=\u001b[39m QuantizationMode(\n\u001b[1;32m    769\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizations, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_spec, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrepresentative_dataset,\n\u001b[1;32m    770\u001b[0m     graph_def, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_experimental_disable_per_channel,\n\u001b[1;32m    771\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexperimental_new_dynamic_range_quantizer,\n\u001b[1;32m    772\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_experimental_low_bit_qat,\n\u001b[1;32m    773\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_experimental_full_integer_quantization_bias_type)\n\u001b[1;32m    774\u001b[0m converter_kwargs\u001b[39m.\u001b[39mupdate({\n\u001b[1;32m    775\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtf_version\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    776\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\u001b[39m.\u001b[39menvironment\u001b[39m.\u001b[39mtensorflowVersion,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    796\u001b[0m         quant_mode\u001b[39m.\u001b[39mactivations_type()\n\u001b[1;32m    797\u001b[0m })\n\u001b[1;32m    798\u001b[0m converter_kwargs\u001b[39m.\u001b[39mupdate(\n\u001b[1;32m    799\u001b[0m     quant_mode\u001b[39m.\u001b[39mconverter_flags(inference_type, inference_input_type))\n",
      "File \u001b[0;32m~/anaconda3/envs/rnd/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:255\u001b[0m, in \u001b[0;36mQuantizationMode.__init__\u001b[0;34m(self, optimizations, target_spec, representative_dataset, graph_def, disable_per_channel, experimental_new_dynamic_range_quantizer, experimental_low_bit_qat, full_integer_quantization_bias_type)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_representative_dataset \u001b[39m=\u001b[39m representative_dataset\n\u001b[1;32m    253\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph_def \u001b[39m=\u001b[39m graph_def\n\u001b[0;32m--> 255\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_int8_required()\n\u001b[1;32m    256\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_disable_per_channel \u001b[39m=\u001b[39m disable_per_channel\n\u001b[1;32m    258\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enable_new_dynamic_range_quantizer \u001b[39m=\u001b[39m (\n\u001b[1;32m    259\u001b[0m     experimental_new_dynamic_range_quantizer)\n",
      "File \u001b[0;32m~/anaconda3/envs/rnd/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:429\u001b[0m, in \u001b[0;36mQuantizationMode._validate_int8_required\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    426\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_target_spec\u001b[39m.\u001b[39msupported_ops \u001b[39m=\u001b[39m {OpsSet\u001b[39m.\u001b[39mTFLITE_BUILTINS_INT8}\n\u001b[1;32m    428\u001b[0m \u001b[39m# Check if representative_dataset is specified.\u001b[39;00m\n\u001b[0;32m--> 429\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_representative_dataset \u001b[39mand\u001b[39;00m\n\u001b[1;32m    430\u001b[0m     \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_quantization_aware_training()):\n\u001b[1;32m    431\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mFor full integer quantization, a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    432\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m`representative_dataset` must be specified.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    434\u001b[0m \u001b[39m# Update represenative dataset to the expected format.\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "tflite_model_path = \"../../results/Coral_iris_model.tflite\"\n",
    "\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(tf_model_path)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = X\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.target_spec.supported_types = [tf.int8]\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "with open(tflite_model_path, 'wb') as f: \n",
    "    f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rnd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f7e8fdd6c7089b66554fb6a2fb9ba4ef5dc66a5cacc103223d0f5e702d5f7a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
